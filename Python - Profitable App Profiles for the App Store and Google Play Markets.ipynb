{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project 1 - Profitable App Profiles for the App Store and Google Play Markets\n",
    "\n",
    "\n",
    "***Guided Project under Dataquest Data Analysis in Python career track***\n",
    "\n",
    "**Author: Yiyan Kang**\n",
    "\n",
    "**Date: January 18th, 2019**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "This project is about anlyzing the App Profiles for the App store and Google Play to help developers understand what kinds of free apps are likely to attract more users. Our goal in this project is to get familiar with Data Analysis in Python."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We found two data sets that can help in this project:\n",
    "\n",
    "* [A data set](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps/home) containing data about approximately seven thousand iOS apps from the App Store, which was collected in July 2017\n",
    "\n",
    "* [A data set](https://www.kaggle.com/lava18/google-play-store-apps/home) containing data about approximately ten thousand Android apps from Google Play, which was collected in August 2018\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make exploring data easier, I created a function `explore_data()` so I can repeatedly to print rows in a more readable way. In addition, I also add an option function to show the number of rows and columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# explore_data() Function\n",
    "# dataset should not contain header row\n",
    "def explore_data(dataset,start,end,rows_and_columns=False):\n",
    "    dataset_slice = dataset[start:end]\n",
    "    for row in dataset_slice:\n",
    "        print(row)\n",
    "        print('\\n') # add a new empty line after each row\n",
    "    \n",
    "    if rows_and_columns:\n",
    "        print(\"Number of rows: \", len(dataset))\n",
    "        print(\"Number of columns: \",len(dataset[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Opening and Exploring Datasets\n",
    "\n",
    "We will start by opening and exploring these two data sets. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from csv import reader\n",
    "\n",
    "# The App Store data set #\n",
    "opened_file1 = open(\"AppleStore.csv\")\n",
    "read_file1 = reader(opened_file1)\n",
    "ios = list(read_file1)\n",
    "ios_header = ios[0]\n",
    "ios_data = ios[1:]\n",
    "\n",
    "print(ios_header)\n",
    "print('\\n')\n",
    "explore_data(ios_data, 0, 5, True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result above, we can see that the Apps Store data set has 7197 rows and 16 columns. For our project, the columns that might be useful for our analysis are 'track_name', 'currency', 'price', 'rating_count_tot', 'rating_count_ver', 'cont_rating' and 'prime_genre'. The explanation of the dataset can be found in the [documentation](https://www.kaggle.com/ramamet4/app-store-apple-data-set-10k-apps/home)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The Google Play Store data set #\n",
    "opened_file2 = open(\"googleplaystore.csv\")\n",
    "read_file2 = reader(opened_file2)\n",
    "gps = list(read_file2)\n",
    "gps_header = gps[0]\n",
    "gps_data = gps[1:]\n",
    "\n",
    "print(gps_header)\n",
    "print(\"\\n\")\n",
    "explore_data(gps_data, 0, 5, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result above, we can see that the Google Play Store data set has 10841 rows and 13 columns. For our project, the columns that might be useful for our analysis are 'App', 'Catagory', 'Rating', 'Reviews', 'Installs', 'Type', 'Price', 'Content Rating' and 'Genres'. The explanation of the dataset can be found in the [documentation](https://www.kaggle.com/lava18/google-play-store-apps/home)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deleting Wrong Data\n",
    "\n",
    "According to the [discussion](https://www.kaggle.com/lava18/google-play-store-apps/discussion/66015) for Google Play Store Dataset, there is one error in entry 10472, where the rating is 19 that is exceeding the highest rating score 5 (because the catagory is missing in this case). Therefore, we need to delete that entry."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gps_data[10472]) # incorrect row\n",
    "print('\\n') \n",
    "print(gps_header) # print header"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(gps_data))\n",
    "del gps_data[10472] # You should not run this line for more than once\n",
    "print(len(gps_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Removing Duplicate Entries\n",
    "\n",
    "When we explore the Google Play data set, we will find that some of the extries are duplicated. For example, Instagram has four entries.\n",
    "\n",
    "##### Google Play Store data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for row in gps_data:\n",
    "    name = row[0]\n",
    "    if name == 'Instagram':\n",
    "        print(row)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We should find the number of cases like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_name = []\n",
    "unique_name = []\n",
    "\n",
    "for row in gps_data:\n",
    "    name = row[0]\n",
    "    if name in unique_name:\n",
    "        duplicate_name.append(name)\n",
    "    else:\n",
    "        unique_name.append(name)\n",
    "print(len(duplicate_name))\n",
    "print(duplicate_name[:20])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 1181 cases where the same name occurs more than once in the data set. We don't want to count the apps more than once when we are analyzing data so we need to delete the other rows. However, randomly deleting the row might not be a good way to deal with this situation.  When we look at the duplicated Instagram example, we can find that the main difference that we care is the number of ratings. In general, the more ratings an app has, the more feedback we are getting. Therefore, we will keep the row with the highest number of reviews and remove the other entries for any given app."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(gps_data)-1181)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The resulted length of the data set after we pick the unique names will be 9659."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews_max = {}\n",
    "for row in gps_data:\n",
    "    name = row[0]\n",
    "    n_reviews = float(row[3])\n",
    "    \n",
    "    if name in reviews_max and reviews_max[name] < n_reviews:\n",
    "        reviews_max[name] = n_reviews\n",
    "    \n",
    "    if name not in reviews_max:\n",
    "        reviews_max[name] = n_reviews\n",
    "print(len(reviews_max))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `reviews_max` dictionary is correct due to the same number we got previously. Then we need to remove the duplicate rows in the Google Play Store dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_clean = [] # will store our new cleaned data set\n",
    "already_added = [] # will store only the names to make sure we don't have duplicate names\n",
    "\n",
    "for row in gps_data:\n",
    "    name = row[0]\n",
    "    n_reviews = float(row[3])\n",
    "    \n",
    "    if n_reviews == reviews_max[name] and name not in already_added:\n",
    "        gps_clean.append(row)\n",
    "        already_added.append(name)\n",
    "\n",
    "explore_data(gps_clean,0,5,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### App Store data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicate_name = []\n",
    "unique_name = []\n",
    "\n",
    "for row in ios_data:\n",
    "    name = row[0]\n",
    "    if name in unique_name:\n",
    "        duplicate_name.append(name)\n",
    "    else:\n",
    "        unique_name.append(name)\n",
    "print(len(duplicate_name))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In conclusion, we removed the duplicate entries in Google Play data set. In addition, we did not forget to check if App Store data set has the same issue; luckily, this situation is not happening in this data set.\n",
    "\n",
    "## Removing Non-English Apps\n",
    "\n",
    "This project is aimed for analysis on apps in English. In both data sets, there exist many apps whose name suggests that they are not direct toward an English-speaking audience."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Some non-English apps in Apple Store:\")\n",
    "print(ios_data[813][1])\n",
    "print(ios_data[6731][1])\n",
    "print(\"\\nSome non-English apps in Google Play Store:\")\n",
    "print(gps_clean[4412][0])\n",
    "print(gps_clean[7940][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are going to remove these rows because we are not interested in them. One way to achieve this is to use ASCII system. English characters and some commonly used symbols are all in the range from 0 to 127. Based on this information, we can simply use the built-in function `ord()` to test the ASCII number of the app name characters. We will use to function to test the rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testEnglish(string):\n",
    "    test = True\n",
    "    count = 0 # for counting the number of non-English characters\n",
    "    for a in string:\n",
    "        if ord(a) < 127 and ord(a) > 0:\n",
    "            test = test\n",
    "        else:\n",
    "            count += 1\n",
    "            if count > 3:\n",
    "                test = False\n",
    "                break\n",
    "    return test\n",
    "\n",
    "print(testEnglish(\"Instagram\"))\n",
    "print(testEnglish(\"爱奇艺PPS -《欢乐颂2》电视剧热播\"))\n",
    "print(testEnglish(\"Docs To Go™ Free Office Suite\"))\n",
    "print(testEnglish(\"Instachat 😜\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this case the function returns `False` only if there are more than three characters that exceed 0 - 127 range. This should make more sense then simply return `False` even if there is only one special character. For example, 'Docs To Go™ Free Office Suite' and 'Instachat 😜' should be considered as English apps. \n",
    "\n",
    "Now we will clean both data sets by using `testEnglish()` function.\n",
    "\n",
    "##### App Store data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ios_eng=[]\n",
    "for row in ios_data:\n",
    "    name = row[1]\n",
    "    if testEnglish(name) == True:\n",
    "        ios_eng.append(row)\n",
    "\n",
    "explore_data(ios_eng,0,3,True)    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we clean the non-English name for App Store data set, it contains 6183 rows and 16 columns.\n",
    "\n",
    "##### Google Play Store data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_eng=[]\n",
    "for row in gps_clean:\n",
    "    name = row[0]\n",
    "    if testEnglish(name) == True:\n",
    "        gps_eng.append(row)\n",
    "\n",
    "explore_data(gps_eng,0,3,True) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After we clean the non-English name for Google Play Store data set, it contains 9614 rows and 13 columns.\n",
    "\n",
    "## Isolating the Free Apps\n",
    "\n",
    "As mentioned in the introduction, we mainly focus on analyzing the apps that are free to download and install. We will need to isolate the free apps in the data set\n",
    "\n",
    "##### App Store data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ios_final = []\n",
    "for row in ios_eng:\n",
    "    price = float(row[4])\n",
    "    if price == 0:\n",
    "        ios_final.append(row)\n",
    "explore_data(ios_final,0,3,True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_final = []\n",
    "for row in gps_eng:\n",
    "    price = row[7]\n",
    "    if price == \"0\":\n",
    "        gps_final.append(row)\n",
    "explore_data(gps_final,0,3,True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we have 3222 rows for App Store data set and 8864 rows for Google Store data set, which should be enough for the analysis.\n",
    "\n",
    "In conclusion, in the data cleaning part, we spend a lot of time on cleaning the data, and\n",
    "\n",
    "* Removed inaccurate data\n",
    "* Removed duplicate app entries\n",
    "* Removed non-English apps\n",
    "* Isolated the free apps\n",
    "\n",
    "As we mentioned in the introduction, our aim is to determine the kinds of apps that are likely to attract more users because our revenue is highly influenced by the number of people using our apps as well as watching the in-app ads.\n",
    "\n",
    "To minimize risks and overhead, our validation strategy for an app idea is comprised of three steps\n",
    "\n",
    "1. Build a minimal Android version of the app, and add it to the Google Play Store.\n",
    "2. If the app has a good response from users, we will develop it further.\n",
    "3. If the app is profitable after six months, we will add a iOS version of the app to the App Store\n",
    "\n",
    "Since our goal is to add the app to both App Store and Google Play Store to minimum variable cost, we need to find app profiles that are successful on both markets. In other words, a profile that might work well for both markets might be a productivity app.\n",
    "\n",
    "We will start by building frequency tables for some columns in our data sets.\n",
    "\n",
    "## Most Common Apps by Genre\n",
    "\n",
    "First, we'll build two functions to generate frequency tables and display the percentages in a descending order."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def freq_table(dataset, index):\n",
    "    table = {}\n",
    "    result = {}\n",
    "    total = 0\n",
    "    for a in dataset:\n",
    "        total += 1\n",
    "        value = a[index]\n",
    "        if value in table:\n",
    "            table[value] += 1\n",
    "        else:\n",
    "            table[value] = 1\n",
    "    \n",
    "    for a in table:\n",
    "        result[a] = table[a]/total*100\n",
    "    return result\n",
    "\n",
    "def display_table(dataset, index):\n",
    "    table = freq_table(dataset, index)\n",
    "    table_display = []\n",
    "    for key in table:\n",
    "        key_val_as_tuple = (table[key], key)\n",
    "        table_display.append(key_val_as_tuple)\n",
    "        \n",
    "    table_sorted = sorted(table_display, reverse = True)\n",
    "    for entry in table_sorted:\n",
    "        print(entry[1], ':', entry[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we will use these two functions to analyze the two data sets.\n",
    "\n",
    "##### App Store data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(ios_final, 11)\n",
    "print(\"Number of Genres: \", len(freq_table(ios_final, 11)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the freqency table, we can see that there are 23 genres in total, where over 50% of the app is under `Games` genre. Another 8% of apps are `Entertainment` genre, followed by 5% `Photo & Video` apps. However, there are only 3.7% of apps are designed for `Education` which is a little bit more than `Social Networking`. \n",
    "\n",
    "In general, we can conclude that in App Store, the apps are mostly designed for fun, like games, entertainment, photo and video, social networking, sports, music and etc., while the apps with more practical uses like education, shopping, utilities, health and fitness, lifestyle and etc. are less in the amount. But we cannot simply look at the freqency table for the apps because the number of apps doesn't mean the popularity; Sometimes, the demand is less than the supply in app.\n",
    "\n",
    "##### Google Play Store data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(gps_final, 1)\n",
    "print(\"Number of Catagory: \", len(freq_table(gps_final,1)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is really interesting and totally different in Google Play Store. We have several genres that are of practice purposes and they have relatively high freqency percentage, like family, tools, business, lifestyle and etc. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(gps_final, 9)\n",
    "print(\"Number of Genres: \", len(freq_table(gps_final,9)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is another column in the data set which can help confirm the better proportion on practical apps.\n",
    "\n",
    "In general, App Store are mostly dominated by fun apps, while Google Play store has a balance between fun apps and practical apps.\n",
    "\n",
    "## Most Popular Apps by Genre\n",
    "\n",
    "One way to find out what genres are the most popular (have the most users) is to calculate the average number of installs for each app genre. For the Google Play data set, we can find this information in the `Installs` column, but this information is missing for the App Store data set. As a workaround, we'll take the total number of user ratings as a proxy, which we can find in the `rating_count_tot` app.\n",
    "\n",
    "Let's start with calculating the average number of user ratings per app genre on the App Store. To do that, we'll need to:\n",
    "\n",
    "* Isolate the apps of each genre\n",
    "* Sum up the user ratings for the apps of that genre\n",
    "* Divide the sum by the number of apps belonging to that genre (not by the total number of apps)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ios_pop_table = freq_table(ios_final, 11)\n",
    "ios_avg_n_rating = {}\n",
    "\n",
    "for unique_genres in ios_pop_table:\n",
    "    total = 0 # store the sum of user ratings specific to each genre\n",
    "    len_genre = 0 # store the number of apps specific to each genre\n",
    "    for row in ios_final:\n",
    "        genre_app = row[11]\n",
    "        if genre_app == unique_genres:\n",
    "            user_rating = float(row[5])\n",
    "            total += user_rating\n",
    "            len_genre += 1\n",
    "    avg_n_rating = total/len_genre\n",
    "    ios_avg_n_rating[unique_genres] = avg_n_rating\n",
    "\n",
    "table_display = []\n",
    "\n",
    "for key in ios_avg_n_rating:\n",
    "    key_val_as_tuple = (ios_avg_n_rating[key], key)\n",
    "    table_display.append(key_val_as_tuple)\n",
    "        \n",
    "ios_sorted_avg_n_rating = sorted(table_display, reverse = True)\n",
    "for entry in ios_sorted_avg_n_rating:\n",
    "    print(entry[1], ':', entry[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the result, we can conclude that the `Navigation` genre has most user ratings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app in ios_final:\n",
    "    if app[11] == 'Navigation':\n",
    "        print(app[1], \": \", app[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is mostly due to the large number in the user rating numbers for Waze and Google Maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app in ios_final:\n",
    "    if app[11] == 'Social Networking':\n",
    "        print(app[1], \": \", app[5])\n",
    "print(\"\\n\")\n",
    "        \n",
    "for app in ios_final:\n",
    "    if app[11] == 'Reference':\n",
    "        print(app[1], \": \", app[5])\n",
    "print(\"\\n\")\n",
    "        \n",
    "for app in ios_final:\n",
    "    if app[11] == 'Music':\n",
    "        print(app[1], \": \", app[5])\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The same situation occurs for other genres. For example, `Facebook` and `Pinterest` in `Social Networking` genre, `Bible` in `Reference` genre and `Pandora`, `Spotify` and `Shazam` in `Music` genre.\n",
    "\n",
    "##### Google Play Store data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "display_table(gps_final, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To make situation easier, though it might not be that precise, we will consider `100,000+` as `100,000`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gps_pop_table = freq_table(gps_final, 1)\n",
    "gps_avg_install = {}\n",
    "\n",
    "for unique_category in gps_pop_table:\n",
    "    total = 0 # store the sum of installs specific to each category\n",
    "    len_category = 0 # store the number of apps specific to each category\n",
    "    \n",
    "    for row in gps_final:\n",
    "        category_app = row[1]\n",
    "        if category_app == unique_category:\n",
    "            n_install = row[5]\n",
    "            n_install = n_install.replace('+','')\n",
    "            n_install = n_install.replace(',','')\n",
    "            total += float(n_install)\n",
    "            len_category += 1\n",
    "                  \n",
    "    avg_install = total/len_category\n",
    "    gps_avg_install[unique_category] = avg_install\n",
    "\n",
    "table_display = []\n",
    "\n",
    "for key in gps_avg_install:\n",
    "    key_val_as_tuple = (gps_avg_install[key], key)\n",
    "    table_display.append(key_val_as_tuple)\n",
    "        \n",
    "gps_sorted_avg_install = sorted(table_display, reverse = True)\n",
    "for entry in gps_sorted_avg_install:\n",
    "    print(entry[1], ':', entry[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "'Communication' apps have most installs followed by 'Video_players' and `Social`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app in gps_final:\n",
    "    if app[1] == 'COMMUNICATION' and (app[5] == '1,000,000,000+'\n",
    "                                      or app[5] == '500,000,000+'\n",
    "                                      or app[5] == '100,000,000+'):\n",
    "        print(app[0], ':', app[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "These catagories contain a lot of giant apps that are hard to compete against so we can start thinking about some genres/categories that are less popular but exist potential to develop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for app in gps_final:\n",
    "    if app[1] == 'BEAUTY' and (app[5] == '500,000+'\n",
    "                                      or app[5] == '5,000,000+'\n",
    "                                      or app[5] == '1,000,000+'):\n",
    "        print(app[0], ':', app[5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For example, the `Beauty` genre includes a variety of apps like makeup, selfie, hairstyles. It seems there's still a small number of extremely popular apps that dominates the installs. \n",
    "\n",
    "## Conclusions\n",
    "In this project, we analyzed data about the App Store and Google Play mobile apps with the goal of recommending an app profile that can be profitable for both markets.\n",
    "\n",
    "We made an conclusion that entering a category that is less popular but has potential to gain users like beauty camera or makeup tips. Besides building on the ideas of the current market, we need to add more brilliant new features to attract users rather than simply copying other's features. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
